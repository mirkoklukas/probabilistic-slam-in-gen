# # # # # # # # # # # # # # # # # # # 
#                                   # 
#   This is an auto-generated file  # 
#   based on the jupyter notebook   # 
#
#   >   ``26 - Slam model - Localization - SMC Move.ipynb''
#
#                                   #
# # # # # # # # # # # # # # # # # # #

push!(LOAD_PATH, "src");
using BenchmarkTools;
using Colors, Plots;
col = palette(:default);
(cgrad::PlotUtils.ContinuousColorGradient)(xs::Vector{Vector{Float64}}) = [cgrad[x] for x in xs];
(cgrad::PlotUtils.ContinuousColorGradient)(m::Matrix{Float64}) = reshape(cgrad[m[:]], size(m));
using Gen
using GridSlam
using Geometry
using MyUtils

Base.Vector(p::Pose) = [p.x;p.hd];

include("unpack_data.jl"); # autogenerated from: "src/unpack_data.jl"

include("slam_stuff_and_utils.jl"); # autogenerated from: "src/slam_stuff_and_utils.jl"
include("pose_prior_model.jl"); # autogenerated from: "src/pose_prior_model.jl"
include("motion_model.jl"); # autogenerated from: "src/motion_model.jl"

function Plots.plot!(p::Pose; r=0.5, args...)
    plot!([p.x, p.x + r*unit_vec(p.hd)]; args...)
end

function Plots.plot!(ps::Vector{Pose}, cs::Vector{RGBA{Float64}}; r=0.5, args...)
    for (p,c) in zip(ps,cs)
        plot!([p.x, p.x + r*unit_vec(p.hd)];c=c, args...)
    end
end

function Plots.plot!(ps::Vector{Pose}; r=0.5, args...)
    for p in ps
        plot!([p.x, p.x + r*unit_vec(p.hd)];args...)
    end
end

using CUDA

function logsumexp_cu(x, dim)
    c = maximum(x)
    return c .+ log.(sum(exp.(x .- c), dims=dim))
end

include("cuda_raycaster_line_map.jl"); # autogenerated from: "src/cuda_raycaster_line_map.jl"

segs_ = CuArray(stack(Vector.(_segs)))

# Todo: Change cast_v4! signature and put z_ in there
#       and replace arg by num_a and fov....
function cast_cu(ps_::CuArray; blockdims=(16,16))
    n = size(segs_, 1)
    m = size(ps_,1)
    z_ = Inf*CUDA.ones(m, n, 360)
    z_ = cast_v4!(segs_,ps_,z_; blockdims=blockdims)

    return z_
end

"""
    ps_ = pose_grid(p, k, delta_x, delta_hd)

Returns CuArray of pose vectors (k^2, 3).
"""
function pose_grid(p, k, delta_x, delta_hd)

    dx1_ = CUDA.collect(CUDA.range(-delta_x,  delta_x, k))
    dx2_ = CUDA.collect(CUDA.range(-delta_x,  delta_x, k))
    dhd_ = CUDA.collect(CUDA.range(-delta_hd/360*π, delta_hd/360*π,k))
    dx1_ = CuArray(dx1_)
    dx2_ = CuArray(dx2_)
    dhd_ = CuArray(dhd_)
    dx1_ = CUDA.repeat(dx1_,  1, k, k)
    dx2_ = CUDA.repeat(reshape(dx2_,1,k,1), k, 1, k)
    dhd_ = CUDA.repeat(reshape(dhd_,1,1,k), k, k, 1)

    ps_ = CUDA.cat(dx1_,dx2_, dhd_, dims=4)
    ps_ = reshape(ps_, :,3)
    ps_ = ps_ .+ reshape(CuArray(Vector(p)),1,3)
    return ps_
end

"""
    slw_kernel!(x, w::Int, y)

CUDA kernel to compute sliding windows...
Takes CuArrays of shape `(k,n)` and `(k,n,m=2w+1)`
and fills the latter with ...
"""
function slw_kernel!(x, w::Int, y)

    m = 2*w + 1

    # Make sure the arrays are
    # of the right shape
    @assert ndims(x)  == 2
    @assert ndims(y)  == ndims(x) + 1
    @assert size(x,1) == size(y,1)
    @assert size(x,2) == size(y,2)
    @assert size(y,3) == m

    # Thread id's
    ix = (blockIdx().x - 1) * blockDim().x + threadIdx().x
    iy = (blockIdx().y - 1) * blockDim().y + threadIdx().y
    iz = (blockIdx().z - 1) * blockDim().z + threadIdx().z
    sx = gridDim().x * blockDim().x
    sy = gridDim().y * blockDim().y
    sz = gridDim().z * blockDim().z

    for j_pose = ix:sx:size(y,1), j_obs = iy:sy:size(y,2), j_mix = iz:sz:size(y,3)
        # Transform `1:m` to `-w:w`
        offset = j_mix-1-w

        # Wrap around, e.g. map `n+1` to `1`
        # Note that we have `size(x,2) == size(y,2)`
        j_mix_adj = mod(j_obs + offset - 1 , size(x,2)) + 1

        # Fill y's
        @inbounds y[j_pose, j_obs, j_mix] = x[j_pose, j_mix_adj]
    end
    return
end

"""
```julia
    y = slw_cu!(x::CuArray, w::Int; blockdims=(8,8,4))
```
Computes sliding windows... takes a CuArray of shape `(k,n)` and returns a CuArray
of shape `(k,n,m)`, where `m = 2w+1`....
"""
function slw_cu!(x::CuArray, w::Int; blockdims=(8,8,4))

    k = size(x, 1)
    n = size(x, 2)
    m = 2*w+1

    y = CUDA.ones(k,n,m)

    griddims = cuda_grid((k,n,m), blockdims)
    CUDA.@sync begin
        @cuda threads=blockdims blocks=griddims slw_kernel!(x, w, y)
    end

    return y
end;

polar_inv_cu(z::CuArray, a::CuArray) = cat(z.*cos.(a), z.*sin.(a), dims=ndims(a)+1);

"""
    ys_tilde_ = get_ys_tilde_cu(zs_::CuArray, w::Int)

Takes depth measurements and returns
the point clouds for the gaussian mixtures ...
"""
function get_ys_tilde_cu(zs_::CuArray, w::Int)
    a_ = CuArray(_as)

    zs_tilde_ = slw_cu!(zs_, w)
    as_tilde_ = slw_cu!(reshape(a_,1,:), w)

    ys_tilde_ = polar_inv_cu(zs_tilde_, as_tilde_)

    return ys_tilde_
end;

"""
    log_p = gaussian_logpdf(x, mu, sig)

Benchmarks in `33 - CUDA Accelerated Gen Distributions` ...
"""
function gaussian_logpdf(x, mu, sig)
    d = (x .- mu).^2 ./ sig.^2
    log_p = - log.(sqrt.(sig * 2 * π)) .- 1/2 * d
    return log_p
end;

"""
    log_p = sensor_smc_logpdf_cu(x::CuArray, ys_tilde::CuArray, sig, dropout)

Evaluates the logpdf of an observation `x` (shape: `(n,2)`)
with respect to a number of different gaussian mixtures stacked along
the first dim of `ys_tilde` (k,n,m,2) ...
"""
function sensor_smc_logpdf_cu(x, ys_tilde, sig, dropout)

    n = size(ys_tilde,2)
    m = size(ys_tilde,3)

    xs = reshape(x, 1, n, 1, 2)

    # Line by line...
    # 1. Compute 1D Gaussians - (n,m,2)
    # 2. Convert to 2D gausians - (n,m)
    # 3. Convert to mixture of m 2D gausians (GM) - (n,)
    # 4. Convert to mixture of `GM` and `anywhere` (D) - (n,)
    # 5. Convert to Product of D's - ()
    log_p = gaussian_logpdf(xs, ys_tilde, sig)
    log_p = sum(log_p, dims=4)[:,:,:,1]
    log_p = logsumexp_cu(log_p .- log(m), 3)[:,:,1]
    log_p_or_any = log.((1-dropout)*exp.(log_p) .+ dropout*1.0)
    log_p = sum(log_p_or_any ,dims=2)[:,1]

    return log_p
end;

perturb(p::Pose, x_noise, hd_noise) = Pose(
    p.x + [normal(0,x_noise); normal(0,x_noise)],
    p.hd + normal(0, hd_noise/360*2π))

function grid_proposals(p::Pose, x::Matrix, w::Int, sig::Float64, dropout, grid_k::Int, grid_dx, grid_dhd)

    # Compute poses to evaluate
    ps_ = pose_grid(p, grid_k, grid_dx, grid_dhd)

    # Compute measurements and gm centers
    zs_ = cast_cu(ps_; blockdims=(16,16));
    ys_tilde_ = get_ys_tilde_cu(zs_, w);

    # Evaluate the gm's
    x_ = CuArray(x)
    log_p_ = sensor_smc_logpdf_cu(x_, ys_tilde_, sig, dropout);

    # Back to CPU
    ps    = Vector.(eachrow(Array(ps_)))
    log_p = Array(log_p_)


    # Sort by log prob
    # and return
    perm  = sortperm(log_p)
    log_p = log_p[perm]
    ps    = ps[perm]

    return ps, log_p
end

function filter_infs(ps, log_p)
    good = log_p .!= -Inf
    return ps[good], log_p[good]
end

@dist function labeled_cat(labels, probs)
    index = categorical(probs)
    labels[index]
end

@gen function grid_proposal(p::Pose, x::Matrix{Float64},
                            w::Int, sig::Float64, dropout::Float64,
                            grid_k::Int, grid_dx::Float64, grid_dhd::Float64)

    ps, log_p = grid_proposals(p, x, w, sig, dropout, grid_k, grid_dx, grid_dhd)
    ps, log_p = filter_infs(ps, log_p)
    probs = exp.(log_p .- logsumexp(log_p))
    j = categorical(probs)
    p_vec = {:pose} ~ labeled_cat(ps, probs)
    return Pose(p_vec), ps, log_p
end

@gen function iterated_proposal(p::Pose, x::Matrix,
                                w::Vector{Int}, sig::Vector{Float64}, dropout::Vector{Float64},
                                grid_k::Vector{Int}, grid_dx::Vector{Float64}, grid_dhd::Vector{Float64})

    n = length(w)

    ps = Pose[]
    log_ps = []
    for i=1:n
        args = (p, x, w[i], sig[i], dropout[i], grid_k[i], grid_dx[i], grid_dhd[i])
        p, _, log_p = {  i => :p } ~ grid_proposal(args...)
        push!(ps, p)
        push!(log_ps, log_p)
    end
    return p, ps, log_ps
end;

include("gen_utils.jl"); # autogenerated from: "src/gen_utils.jl"

function sensor_logpdf_cu(x::CuArray, y_tilde::CuArray, sig, dropout)
    n = size(y_tilde,1)
    m = size(y_tilde,2)

    @assert size(x,1) == size(y_tilde,1)

    x = reshape(x, n, 1, 2)

    # Compute 1D Gaussians - (n,m,2)
    # Convert to 2D gausians - (n,m)
    # Convert to mixture of m 2D gausians (GM) - (n,)
    # Convert to mixture of `GM` and `anywhere` (D) - (n,)
    # Convert to Product of D's - ()
    log_p = gaussian_logpdf(x, y_tilde, sig)
    log_p = sum(log_p, dims=3)[:,:,1]
    log_p = logsumexp_cu(log_p .- log(m), 2)[:,1]
    log_p_or_any_ = log.((1-dropout)*exp.(log_p) .+ dropout*1.0)
    log_p = sum(log_p_or_any_)
    return log_p
end

struct SensorDistribution_CUDA <: Distribution{Vector{Vector{Float64}}}
end

const sensordist_cu = SensorDistribution_CUDA()

function Gen.logpdf(::SensorDistribution_CUDA, x, y_tilde_::CuArray, sig, dropout)
    x_ = CuArray(stack(x))
    return sensor_logpdf_cu(x_, y_tilde_, sig, dropout)
end
function Gen.random(::SensorDistribution_CUDA, y_tilde_::CuArray, sig, dropout)
    n = size(y_tilde_,1)
    m = size(y_tilde_,2)

    x = Vector{Float64}[]
    for i=1:n
        if bernoulli(dropout)
            x_i = [Inf;Inf]
        else
            j = rand(1:m)
            y = Array(y_tilde_[i,j,:])
            x_i = diagnormal(y, [sig;sig])

        end
        push!(x, x_i)
    end
    return x
end

(D::SensorDistribution_CUDA)(args...) = Gen.random(D, args...)
Gen.has_output_grad(::SensorDistribution_CUDA)    = false
Gen.has_argument_grads(::SensorDistribution_CUDA) = (false, false);

@gen function sensor_model_GPU(p, w, s_noise, dropout)
    p_ = CuArray(Vector(p))
    zs_      = cast_cu(reshape(p_, 1,3))
    y_tilde_ = get_ys_tilde_cu(zs_, w)[1,:,:,:];

    x ~ sensordist_cu(y_tilde_, s_noise, dropout)
    return x
end

@gen function slam_kernel(t, state, us, x_noise, hd_noise, w, s_noise, dropout)

        p,_ = state
        u = us[t]

        p  = {:pose}   ~ motion_model(p, u, x_noise, hd_noise)
        x  = {:sensor} ~ sensor_model_GPU(p, w, s_noise, dropout) # GPU accelerated

    return (p, x)
end

slam_chain = Gen.Unfold(slam_kernel)
Gen.@load_generated_functions

"""
    [(p,z),...] = static_slam_model(T, segs_, a_, us, motion_noise, sensor_noise, dropout, inds)

Static SLAM model ...
"""
@gen (static) function static_slam_model(T, us,
        p0, x0_noise, hd0_noise,
        x_noise, hd_noise,
        w, s_noise, dropout)

    # Start the Markov chain;
    # No motion, just the prior
    p  = { :pose   } ~ pose_prior_model(p0, x0_noise, hd0_noise)
    x  = { :sensor } ~ sensor_model_GPU(p, w, s_noise, dropout) # GPU accelerated

    # Unfold the MArkov chain
    chain ~ slam_chain(T, (p, nothing), us,
        x_noise, hd_noise,
        w, s_noise, dropout)

    return [(p,x);chain]
end

Gen.@load_generated_functions

get_pose(tr,t)     = tr[][t][1]
get_last_pose(tr)  = tr[][end][1]
get_first_pose(tr) = get_pose(tr,1)

get_x(tr,t)     = tr[][t][2]
get_first_x(tr) = get_x(tr,1)

function extend(tr, obs, grid_args)

    args  = get_args(tr)
    diffs = argdiffs([1;fill(0,length(args))])
    t = args[1]
    x = stack(obs[:chain => t+1 => :sensor => :x])

    p = get_last_pose(tr)
    proposal_tr = simulate(iterated_proposal, (p, x, grid_args...));
    proposal_sc = get_score(proposal_tr)
    p′, = proposal_tr[];


    ch = choicemap()
    ch[:chain => t+1 => :pose => :x]  = p′.x
    ch[:chain => t+1 => :pose => :hd]  = p′.hd

    tr′,w′,_,_ = Gen.update(tr,(t+1,args[2:end]...),diffs,merge(obs,ch))

    return tr′, w′ - proposal_sc

end

function constraints(t::Int)
    ch = choicemap()
    if t==0
        addr  = :sensor => :x
    else
        addr  = :chain => t => :sensor => :x
    end
    n = length(_zs[t+1])
    x = polar_inv(_zs[t+1],_as)
    ch[addr] = x
    return ch
end
